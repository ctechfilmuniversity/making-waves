+++
title = "Making Waves WS22/23"
date = "2023-01-30"
author = "Winter"
hideComments=true
+++

The Making Waves workshop series aimed to introduce students to generative compositional techniques in the context of live performance. Each session began with a brief theoretical introduction, followed by practical demonstrations and an open session for students to apply what they had learned to their final performance.

During the final performances, students from diverse backgrounds had the opportunity to showcase their existing work, collaborate on a unified audio-visual piece, or perform their own 15-minute live set. The open workshop format allowed students to design their individual setups based on their unique artistic goals and needs, while also giving the workshop room to grow and refine its focus over time.

The recordings of the final performances can be found [here](https://github.com/Myxxin/Making-Waves-Retrospective/tree/main/final_recordings).

## Session One - Inspiration and Exploration

The first session of the workshop aimed to provide visual inspiration and an overview of the available musical tools to the students. After introducing the concept of generative algorithms and their ability to create data similar to existing data, the students were given local installations of the Stable Diffusion image generation AI. They explored the power of this particular generative model and created potential mood boards for their future performances

![cat](https://user-images.githubusercontent.com/93442123/224561542-e3ef4463-69a9-483f-ad23-7ce9c8712c5c.png)
![king crimson](https://user-images.githubusercontent.com/93442123/224561546-b6167e73-9c9a-4118-99b0-a79ea5851d74.png)
![steampunk-flower](https://user-images.githubusercontent.com/93442123/224561549-88358dda-2e81-474f-9d20-40931f1ab7c4.png)

However, the technical introduction to the inner workings of AI went over the heads of most students, including the creative technologists. As a result, AI was not further utilized in the course.

During the second half of the workshop, the students had the opportunity to explore the musical devices of the Creative Technologies program with the guidance of the lecturers. This part of the session was well-received and included the following devices:

* MPC LIVE II
* Elektron Digitone
* Roland MC 707
* Multiple Korg Volcas
* Synthstrom Deluge
* Korg Minilogue
* Critter & Guitari Organelle

## Session Two - Sound Synthesis
The second session of the workshop aimed to provide the students with a solid understanding of sound synthesis fundamentals while also encouraging them to experiment with more left-field methods. Marco Winter gave the first presentation, which largely focused on subtractive and demonstrated with the [Ableton Wavetable synthesizer](https://www.ableton.com/de/packs/wavetable/).

![synthesis](https://user-images.githubusercontent.com/93442123/224562024-4d1ccd50-3faa-447f-bcfe-b1d0d39f23c3.jpg)

Lara's presentation focused on her own work, influences, and techniques. She took a different approach, highlighting granular synthesis using orchestral samples as an alternative and more explorative way of creating sounds.

![lara](https://user-images.githubusercontent.com/93442123/224565359-320e0252-161d-4058-bc26-e747a61eb141.JPG)

## Session Three - Resolume
The third session took a break from the music-focused sessions and shifted the focus to creating visuals to complement the final performances. The students presented songs that inspire them and created a shared playlist to get to know each other better, which can be accessed here: [shared playlist](https://open.spotify.com/playlist/7loq1NhkBNZHofEJ2ye6yU?si=9ad230fdd12c4b2c).



After the warmup, Rita introduced the class to the powerful VJing software, Resolume.


## Session Four - Generative Techniques in Ableton Live and Max for Live
Session four delved deeper into the generative capabilities of Ableton Live and Max Msp/Max for Live. The first part of the session focused on generative techniques built into Ableton Live, such as following action, midi probability, and LFO-driven sound design.



https://user-images.githubusercontent.com/93442123/224732877-46b6915d-66b8-4d4c-b651-21a01075251e.MP4



In the second part of the theoretical session, Justin Robinson led a presentation on his generative instrument, Pärtinator, and provided an overview of the Max MSP visual programming environment.

## Final Performances
## Andreea, Jonathan & Enrique

![Folie1](https://user-images.githubusercontent.com/93442123/225284679-77fa05ce-b10b-44f8-9349-a30f9e23ef38.JPG)

https://user-images.githubusercontent.com/93442123/224740964-1b4b6efb-0295-4a78-b2b8-f2d96ba3a3f3.mp4

Andreea, Jonathan, and Enrique combined their favorite techniques and tools from the workshop with their own recordings and live vocals to create a shared hybrid setup. They began with a set of self-recorded piano samples and processed them using Ableton Live and its Simpler instrument by slicing, reversing, and other effects. As the tune progressed, the piano sound was backed rhythmically by drums, bass, and a heartbeat sample. To play back their prepared clips during the performance, they used a Launchpad.

The Synthstrom Deluge played the prominent brassy synth tone, which was routed into Ableton Live. Andreea's vocals were the guiding force throughout the song, picked up by two microphones. The first was mixed with generous reverb and delay in Ableton Live, while the second was routed to a second computer. The lyrics, generated by the ChatGPT text generation AI, were about "making waves" and matched the visuals perfectly.



https://user-images.githubusercontent.com/93442123/225325434-869cfcbe-e148-42ac-a31f-465a24ecec82.MOV



The group prepared three layers of visuals using Resolume: abstract and realistic stock footage, and their own wave-like line animations created in Procreate. They would switch and blend between these layers during the performance, using the volume of the second microphone to control additional effects such as scaling or mirroring.

However, reflecting on their performance, the setup proved to be too complicated. Their computers struggled with the workload, and all the different tools were challenging to handle simultaneously. For their next performance, they streamlined their setup significantly with the help of a hardware mixer. Looking back, they realized that an additional workshop day to prepare for the live performance would have been tremendously helpful in addressing these issues.

## Marco


![Folie1](https://user-images.githubusercontent.com/93442123/224735932-975650eb-c54f-4ad8-b3ba-7dee26a00295.PNG)


https://user-images.githubusercontent.com/93442123/223133333-6ec67e04-13e3-4808-8038-8fb97e67b1bb.mp4


For my performance, I opted for a dawless setup comprising of an Elektron Syntakt 12 track mono-synth and a Digitone FM 4 track poly-synth. I routed the Digitone into the Syntakt's inputs to benefit from its analog fx track and also to smoothly bring in a new track with the digitone master gain.

Both devices' data structure can be categorized as Project>Songs>Patterns>Tracks>Sounds. With the recent addition of song mode, I could conveniently queue songs/patterns and switch between pre-recorded sequences, achieving the desired balance between structure and improvisation. However, at present, it's not possible to pre-assign which patterns should play in loop mode by default (each pattern plays for a specific number of loops). So, if a pattern needs to loop for a while, it demands good coordination across both devices.

I was very pleased with this setup's sound quality - I designed every sound from scratch for the first time. However, except for the short intro, the songs didn't entirely resonate with me, so I plan to streamline things further. My next objective is to integrate both devices into a Daw environment using the Overbridge VST. This way, I can use Ableton Live as a mixer to refine the sound, play samples, and experiment with various FX techniques.

## Stefan

![Folie1](https://user-images.githubusercontent.com/93442123/224736378-0a3fbd59-9149-4963-9200-3c2ee2709d29.PNG)



https://user-images.githubusercontent.com/93442123/224733261-28c2e2a3-7702-46ef-a7cd-93ad7e551322.mp4


For his setup Stefan Püst, went dawless as well, connecting his Roland MC 707 to his Octatrack.
He utilized the MC 707 to combine multiple prerecorded instrument loops and create full arrangements. By muting, fading in/out, and swapping individual loops, he constructed an overarching structure for his performance. Additionally, he used the Octatrack to play prepared transition effects, with the patterns containing effects automations like filter sweeps. Stefan relied on the A/B fader of the Octatrack as a Dry/Wet control to switch to the effect-mangled version of his track at the appropriate moment.
